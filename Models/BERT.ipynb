{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d500f346-7d2f-4edc-88c8-1f34fb78441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "model_path = \"./bert_model.onnx\"\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# set the model to inference mode\n",
    "# It is important to call torch_model.eval() or torch_model.train(False) before exporting the model, \n",
    "# to turn the model to inference mode. This is required since operators like dropout or batchnorm \n",
    "# behave differently in inference and training mode.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd38175-9cf3-4e68-a747-238ea642608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy inputs to the model. Adjust if neccessary.\n",
    "inputs = {\n",
    "        # list of numerical ids for the tokenized text\n",
    "        'input_ids':   torch.randint(32, [1, 32], dtype=torch.long), \n",
    "        # dummy list of ones\n",
    "        'attention_mask': torch.ones([1, 32], dtype=torch.long),     \n",
    "        # dummy list of ones\n",
    "        'token_type_ids':  torch.ones([1, 32], dtype=torch.long)     \n",
    "    }\n",
    "\n",
    "symbolic_names = {0: 'batch_size', 1: 'max_seq_len'}\n",
    "torch.onnx.export(model,                                         \n",
    "# model being run \n",
    "                  (inputs['input_ids'],\n",
    "                   inputs['attention_mask'], \n",
    "                   inputs['token_type_ids']),                    # model input (or a tuple for multiple inputs)\n",
    "                  model_path,                                    # where to save the model (can be a file or file-like object)\n",
    "                  opset_version=11,                              # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,                      # whether to execute constant folding for optimization\n",
    "                  input_names=['input_ids',\n",
    "                               'input_mask', \n",
    "                               'segment_ids'],                   # the model's input names\n",
    "                  output_names=['start_logits', \"end_logits\"],   # the model's output names\n",
    "                  dynamic_axes={'input_ids': symbolic_names,\n",
    "                                'input_mask' : symbolic_names,\n",
    "                                'segment_ids' : symbolic_names,\n",
    "                                'start_logits' : symbolic_names, \n",
    "                                'end_logits': symbolic_names})   # variable length axes/dynamic input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0d770-781d-405c-ac05-15d63b9e8b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
